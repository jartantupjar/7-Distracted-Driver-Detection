{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "import cv2\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "import matplotlib.pyplot as plt     \n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import optimizers\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.models import Model\n",
    "def model_history(history):\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model):\n",
    "    json_string = model.to_json()\n",
    "    if not os.path.isdir('cache'):\n",
    "        os.mkdir('cache')\n",
    "    open(os.path.join('cache', 'model_vgg16.json'), 'w').write(json_string)\n",
    "\n",
    "\n",
    "def read_model():\n",
    "    model = model_from_json(open(os.path.join('cache', 'model_vgg16.json')).read())\n",
    "    return model\n",
    "\n",
    "def create_submission(predictions, test_id, loss):\n",
    "    print('Started building csv file')\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result1.insert(loc=0, column='img', value=test_id)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = str(round(loss, 6)) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)\n",
    "    print(\"successfully created submission\")   \n",
    "    \n",
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "\n",
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def read_imc(path):\n",
    "    # Load as grayscale\n",
    "    #img = cv2.imread(path, 0)\n",
    "    # Reduce size\n",
    "    #resized = cv2.resize(img, (224, 224))\n",
    "    #x = image.img_to_array(path)\n",
    "    #resized=np.expand_dims(x, axis=0)\n",
    "    img = cv2.imread(path)\n",
    "    img_rows, img_cols=224,224\n",
    "   # resized = cv2.resize(img, (96, 128), cv2.INTER_LINEAR)\n",
    "    resized = cv2.resize(img, (img_rows, img_cols))\n",
    "    return resized\n",
    "\n",
    "def get_driver_data():\n",
    "    dr = dict()\n",
    "    clss = dict()\n",
    "    path ='Data/driver_imgs_list.csv'\n",
    "    print('Read drivers data')\n",
    "    f = open(path, 'r')\n",
    "    line = f.readline()\n",
    "    while (1):\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        arr = line.strip().split(',')\n",
    "        dr[arr[2]] = arr[0]\n",
    "        if arr[0] not in clss.keys():\n",
    "            clss[arr[0]] = [(arr[1], arr[2])]\n",
    "        else:\n",
    "            clss[arr[0]].append((arr[1], arr[2]))\n",
    "    f.close()\n",
    "    return dr, clss\n",
    "\n",
    "def load_train():\n",
    "    #path='Data/imgs/train'\n",
    "    #data=load_files(path)\n",
    "    #driver_file=np.array(data['filenames'])\n",
    "    #driver_target=np_utils.to_categorical(np.array(data['target']),10)\n",
    "    #data=glob(path)\n",
    "    driver_file=[]\n",
    "    driver_target=[]\n",
    "    driver_id=[]\n",
    "    driver_file_id=[]\n",
    "    driver_data, dr_class = get_driver_data()\n",
    "    print('driver data and class sample',len(driver_data),len(dr_class))\n",
    "    for j in range(10):\n",
    "        print('Load folder c{}'.format(j))\n",
    "        path = os.path.join( 'Data', 'imgs', 'train', 'c' + str(j), '*.jpg')\n",
    "        data = glob(path)\n",
    "        for p in data:\n",
    "            \n",
    "            driver_file.append(read_imc(p))\n",
    "            driver_target.append(j)\n",
    "            base = os.path.basename(p)\n",
    "            driver_file_id.append(base)\n",
    "            driver_id.append(driver_data[base])\n",
    "            #print(driver_data[base])\n",
    "    unique_drivers = sorted(list(set(driver_id)))\n",
    "    print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "    print(unique_drivers)\n",
    "    return driver_file,driver_target,driver_file_id,driver_id,unique_drivers\n",
    "\n",
    "def load_test():\n",
    "    path='Data/imgs/test/*'\n",
    "    data=glob(path)\n",
    "    driver_file=[]\n",
    "    driver_id=[]  \n",
    "    for p in data:\n",
    "        driver_file.append(read_imc(p))\n",
    "        driver_id.append(os.path.basename(p))\n",
    "        \n",
    "   # driver_id=os.path.basename(p)\n",
    "    #test_id=np.array(driver_file['target'])\n",
    "    return driver_file,driver_id\n",
    "\n",
    "def split_list_trial(l,size):\n",
    "    return [l[i:i + size] for i in range(0, len(l), size)]\n",
    "\n",
    "def split_list(l,size):\n",
    "    return [l[i*len(l) // size: (i+1)*len(l) // size] for i in range(size)]\n",
    "\n",
    "def load_test_parts(part,splits):\n",
    "    path='Data/imgs/test/*'\n",
    "    data=glob(path)\n",
    "    driver_file=[]\n",
    "    driver_id=[]  \n",
    "    test_chunks=split_list(data,splits)\n",
    "    \n",
    "    for p in test_chunks[part]:\n",
    "        driver_file.append(read_imc(p))\n",
    "        driver_id.append(os.path.basename(p))\n",
    "        \n",
    "    #del data\n",
    "    #del test_chunks\n",
    "   # driver_id=os.path.basename(p)\n",
    "    #test_id=np.array(driver_file['target'])\n",
    "    return driver_file,driver_id\n",
    "\n",
    "def append_chunk(main, part):\n",
    "    for p in part:\n",
    "        main.append(p)\n",
    "        \n",
    "    return main\n",
    "def print_sample(data,target):\n",
    "    print (\"X shape\",data.shape) \n",
    "    print (\"Y shape\",target.shape)\n",
    "    \n",
    "   # for p in data[:2]: print (p)\n",
    "  #  for p in target[:2]: print (p)\n",
    "    #im = cv2.imread(data[1])\n",
    "    # show sample image   \n",
    "    #plt.imshow(im)\n",
    "    #plt.show()\n",
    "    return None\n",
    "\n",
    "def get_selected_drivers(train_data, train_target, driver_id, driver_list):\n",
    "    data = []\n",
    "    target = []\n",
    "   \n",
    "    for i in range(len(train_data)):\n",
    "        if driver_id[i] in driver_list:\n",
    "            data.append(train_data[i])\n",
    "            target.append(train_target[i])\n",
    "            \n",
    "    data = np.array(data)\n",
    "    target = np.array(target)\n",
    "    print('driver list length',len(driver_list))\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def data_split(data,target,test_size,driver_id,driver_list):\n",
    " #   if unique==True:\n",
    "        \n",
    "       # perm = np.random.permutation(len(target))\n",
    "        #x,y = data[perm], target[perm]\n",
    "        #unique_list_train = [unique_drivers[i] for i in train_drivers]\n",
    "        \n",
    "        #drivers_list=drivers_list[perm]\n",
    "        random.shuffle(driver_list)\n",
    "        #test_size=0.2\n",
    "        test_split=test_size*len(driver_list)\n",
    "        test_split=int(round(test_split))\n",
    "       \n",
    "        train_list=driver_list[test_split:]\n",
    "        test_list=driver_list[:test_split]\n",
    "        \n",
    "        X_train,y_train = get_selected_drivers(data,target,driver_id,train_list)\n",
    "        X_test,y_test = get_selected_drivers(data,target,driver_id,test_list)\n",
    "        \n",
    "       # perm = np.random.permutation(len(y_train))\n",
    "       # X_train,y_train = X_train[perm], y_train[perm]\n",
    "        \n",
    "       # perm = np.random.permutation(len(y_test))\n",
    "       # X_test,y_test = X_test[perm], y_test[perm]\n",
    "        \n",
    "       # print('Train shape',train_list )\n",
    "       # print('Test shape',test_list)\n",
    "\n",
    "  #  else:    \n",
    "   #     X_train, X_split, y_train, y_split = train_test_split(data,target,test_size=test_size,random_state=42)\n",
    "    \n",
    "        return X_train, X_test, y_train, y_test, test_list\n",
    "    \n",
    "img_rows=224\n",
    "img_cols=224\n",
    "img_channel=3  \n",
    "\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore train from cache\n",
      "driver list length 18\n",
      "driver list length 8\n",
      "driver list length 5\n",
      "driver list length 3\n",
      "building train cache\n",
      "train cache built\n",
      "building val cache\n",
      "val cache built\n",
      "building test cache\n",
      "test cache built\n"
     ]
    }
   ],
   "source": [
    "# SECTION USED ONLY TO SPLIT DATA\n",
    "\n",
    "cache_path= os.path.join('cache','train_224.dat')\n",
    "if not os.path.isfile(cache_path):\n",
    "    print('building train cache')\n",
    "    train_files,train_targets,train_id, driver_id, unique_drivers = load_train()\n",
    "    cache_data((train_files,train_targets,train_id, driver_id, unique_drivers),cache_path)\n",
    "    print('train cache built')           \n",
    "else:\n",
    "    print('Restore train from cache')\n",
    "    (train_files,train_targets,train_id, driver_id, unique_drivers)=restore_data(cache_path)\n",
    "\n",
    "train_files=np.array(train_files,dtype=np.uint8)\n",
    "\n",
    "train_files = train_files.reshape(train_files.shape[0], img_rows, img_cols,img_channel)\n",
    "\n",
    "\n",
    "test_size=0.3\n",
    "X_train, X_split, y_train, y_split,split_driver_list =data_split(train_files,train_targets,test_size,driver_id,unique_drivers)\n",
    "\n",
    "del train_files\n",
    "del train_targets\n",
    "\n",
    "test_size=0.4\n",
    "X_test, X_val, y_test, y_val,val_driver_list = data_split(X_split,y_split,test_size,driver_id,split_driver_list)\n",
    "\n",
    "cache_path= os.path.join('cache','train_split_224.dat')\n",
    "if not os.path.isfile(cache_path):\n",
    "    print('building train cache')\n",
    "    cache_data((X_train,y_train),cache_path)\n",
    "    print('train cache built')           \n",
    "\n",
    "    \n",
    "cache_path= os.path.join('cache','val_split_224.dat')\n",
    "if not os.path.isfile(cache_path):\n",
    "    print('building val cache')\n",
    "    cache_data((X_val,y_val),cache_path)\n",
    "    print('val cache built')           \n",
    "\n",
    "    \n",
    "cache_path= os.path.join('cache','test_split_224.dat')\n",
    "if not os.path.isfile(cache_path):\n",
    "    print('building test cache')\n",
    "    cache_data((X_test,y_test),cache_path)\n",
    "    print('test cache built')           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore train split from cache\n",
      "Restore val split from cache\n",
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_1\n",
      "13 block2_pool\n",
      "14 batch_normalization_1\n",
      "15 add_1\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_2\n",
      "23 block3_pool\n",
      "24 batch_normalization_2\n",
      "25 add_2\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_3\n",
      "33 block4_pool\n",
      "34 batch_normalization_3\n",
      "35 add_3\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_4\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_5\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_6\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_7\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_8\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_9\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_10\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_11\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_4\n",
      "123 block13_pool\n",
      "124 batch_normalization_4\n",
      "125 add_12\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, 111, 111, 32)  864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, 111, 111, 32)  128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, 111, 111, 32)  0           block1_conv1_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, 109, 109, 64)  18432       block1_conv1_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, 109, 109, 64)  256         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, 109, 109, 64)  0           block1_conv2_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, 109, 109, 128) 8768        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, 109, 109, 128) 512         block2_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, 109, 109, 128) 0           block2_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, 109, 109, 128) 17536       block2_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, 109, 109, 128) 512         block2_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 55, 55, 128)   8192        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 55, 55, 128)   0           block2_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 55, 55, 128)   512         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 55, 55, 128)   0           block2_pool[0][0]                \n",
      "                                                                   batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, 55, 55, 128)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, 55, 55, 256)   33920       block3_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, 55, 55, 256)   1024        block3_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, 55, 55, 256)   0           block3_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, 55, 55, 256)   67840       block3_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, 55, 55, 256)   1024        block3_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 28, 28, 256)   32768       add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 28, 28, 256)   1024        conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_2 (Add)                      (None, 28, 28, 256)   0           block3_pool[0][0]                \n",
      "                                                                   batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, 28, 28, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, 28, 28, 728)   188672      block4_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, 28, 28, 728)   2912        block4_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, 28, 28, 728)   0           block4_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, 28, 28, 728)   536536      block4_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, 28, 28, 728)   2912        block4_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 14, 14, 728)   186368      add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 728)   0           block4_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 14, 14, 728)   2912        conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 14, 14, 728)   0           block4_pool[0][0]                \n",
      "                                                                   batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block5_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block5_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, 14, 14, 728)   0           block5_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block5_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block5_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, 14, 14, 728)   0           block5_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block5_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block5_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 14, 14, 728)   0           block5_sepconv3_bn[0][0]         \n",
      "                                                                   add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block6_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block6_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, 14, 14, 728)   0           block6_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block6_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block6_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, 14, 14, 728)   0           block6_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block6_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block6_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 14, 14, 728)   0           block6_sepconv3_bn[0][0]         \n",
      "                                                                   add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block7_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block7_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, 14, 14, 728)   0           block7_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block7_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block7_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, 14, 14, 728)   0           block7_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block7_sepconv3_act[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block7_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 14, 14, 728)   0           block7_sepconv3_bn[0][0]         \n",
      "                                                                   add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block8_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block8_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, 14, 14, 728)   0           block8_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block8_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block8_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, 14, 14, 728)   0           block8_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block8_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block8_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 14, 14, 728)   0           block8_sepconv3_bn[0][0]         \n",
      "                                                                   add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block9_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block9_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, 14, 14, 728)   0           block9_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block9_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block9_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, 14, 14, 728)   0           block9_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block9_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block9_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 14, 14, 728)   0           block9_sepconv3_bn[0][0]         \n",
      "                                                                   add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, 14, 14, 728)   0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block10_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block10_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, 14, 14, 728)   0           block10_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, 14, 14, 728)   536536      block10_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, 14, 14, 728)   2912        block10_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, 14, 14, 728)   0           block10_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, 14, 14, 728)   536536      block10_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, 14, 14, 728)   2912        block10_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 14, 14, 728)   0           block10_sepconv3_bn[0][0]        \n",
      "                                                                   add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, 14, 14, 728)   0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block11_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block11_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, 14, 14, 728)   0           block11_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, 14, 14, 728)   536536      block11_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, 14, 14, 728)   2912        block11_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block11_sepconv3_act (Activation (None, 14, 14, 728)   0           block11_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, 14, 14, 728)   536536      block11_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, 14, 14, 728)   2912        block11_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 14, 14, 728)   0           block11_sepconv3_bn[0][0]        \n",
      "                                                                   add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, 14, 14, 728)   0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block12_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block12_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, 14, 14, 728)   0           block12_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, 14, 14, 728)   536536      block12_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, 14, 14, 728)   2912        block12_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, 14, 14, 728)   0           block12_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, 14, 14, 728)   536536      block12_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, 14, 14, 728)   2912        block12_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 14, 14, 728)   0           block12_sepconv3_bn[0][0]        \n",
      "                                                                   add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, 14, 14, 728)   0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block13_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block13_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, 14, 14, 728)   0           block13_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, 14, 14, 1024)  752024      block13_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, 14, 14, 1024)  4096        block13_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 7, 7, 1024)    745472      add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, 7, 7, 1024)    0           block13_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 7, 7, 1024)    4096        conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 7, 7, 1024)    0           block13_pool[0][0]               \n",
      "                                                                   batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, 7, 7, 1536)    1582080     add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, 7, 7, 1536)    6144        block14_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, 7, 7, 1536)    0           block14_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, 7, 7, 2048)    3159552     block14_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, 7, 7, 2048)    8192        block14_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, 7, 7, 2048)    0           block14_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 2048)          0           block14_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          2098176     global_average_pooling2d_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            10250       dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 22,969,906\n",
      "Trainable params: 0\n",
      "Non-trainable params: 22,969,906\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 00000: val_loss improved from inf to 2.11024, saving model to saved_models/weightsfromscratch.hdf5\n",
      "Epoch 00001: val_loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ndrs\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\ndrs\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ndrs\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 568, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"C:\\Users\\ndrs\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 737, in __next__\n",
      "    return self.next(*args, **kwargs)\n",
      "  File \"C:\\Users\\ndrs\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 811, in next\n",
      "    batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n",
      "MemoryError\n",
      "\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bbc12c62279e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    105\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                             callbacks=[checkpointer],verbose=0)\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ndrs\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ndrs\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2062\u001b[0m                                 \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                                 use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   2065\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m                             \u001b[1;31m# No need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ndrs\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ndrs\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2159\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2160\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2161\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cache_path= os.path.join('cache','train_split_224.dat')   \n",
    "if os.path.isfile(cache_path):\n",
    "    print('Restore train split from cache')\n",
    "    (X_train,y_train)=restore_data(cache_path)\n",
    "else:\n",
    "    print('train split data cache is empty')\n",
    "    \n",
    "X_train=np.array(X_train,dtype=np.uint8)\n",
    "y_train=np.array(y_train,dtype=np.uint8)\n",
    "y_train=np_utils.to_categorical(y_train,10)\n",
    "\n",
    "#train_files = train_files.reshape(train_files.shape[0], img_rows, img_cols,img_channel)\n",
    "    \n",
    "    \n",
    "cache_path= os.path.join('cache','val_split_224.dat')   \n",
    "if os.path.isfile(cache_path):\n",
    "    print('Restore val split from cache')\n",
    "    (X_val,y_val)=restore_data(cache_path)\n",
    "else:\n",
    "    print('val split data cache is empty')\n",
    "    \n",
    "X_val=np.array(X_val,dtype=np.uint8)\n",
    "y_val=np.array(y_val,dtype=np.uint8)\n",
    "y_val=np_utils.to_categorical(y_val,10)   \n",
    "\n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "   rescale=1./255,\n",
    "   #shear_range=0.2,\n",
    "   zoom_range=0.2,\n",
    "   width_shift_range=0.1,\n",
    "   height_shift_range=0.1, \n",
    "   horizontal_flip=False\n",
    "    \n",
    "    )\n",
    "\n",
    "val_datagen=ImageDataGenerator(\n",
    "   rescale=1./255, \n",
    "   zoom_range=0.1,\n",
    "   width_shift_range=0.1,\n",
    "   height_shift_range=0.1, \n",
    "   horizontal_flip=False\n",
    "    )\n",
    "\n",
    "train_datagen.fit(X_train)\n",
    "val_datagen.fit(X_val)\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "base_model = Xception(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(train_datagen.flow(X_train,y_train,batch_size=batch_size),\n",
    "                        \n",
    "                    steps_per_epoch=len(X_train)//batch_size,epochs=3,\n",
    "                            verbose=0)\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weightsfromscratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "epochs=7\n",
    "\n",
    "history=model.fit_generator(train_datagen.flow(X_train,y_train,batch_size=batch_size),\n",
    "                            validation_data=val_datagen.flow(X_val,y_val),\n",
    "                    steps_per_epoch=len(X_train)//batch_size,validation_steps=len(X_val)//batch_size,epochs=epochs,\n",
    "                            callbacks=[checkpointer],verbose=0)\n",
    "save_model(model)\n",
    "model_history(history)\n",
    "\n",
    "\n",
    "#model.load_weights('saved_models/weightsfromscratch.hdf5')\n",
    "#score = model.evaluate(X_test, y_test, verbose=1)\n",
    "#print(score)\n",
    "\n",
    "cache_path= os.path.join('cache','test_split_224.dat')    \n",
    "if os.path.isfile(cache_path):\n",
    "    print('Restore test split from cache')\n",
    "    (X_test,y_test)=restore_data(cache_path)\n",
    "else:\n",
    "    print('Test split data cache is empty')\n",
    "X_test=np.array(X_test,dtype=np.uint8)\n",
    "y_test=np.array(y_test,dtype=np.uint8)\n",
    "y_test=np_utils.to_categorical(y_test,10)   \n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test/=255\n",
    "predictions=model.predict(X_test, verbose=0)\n",
    "score=log_loss(y_test,predictions)\n",
    "print('Score log_loss: ', score)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score log_loss:  2.30171723618\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read and compiled model\n"
     ]
    }
   ],
   "source": [
    "model = read_model()\n",
    "model.load_weights('saved_models/weightsfromscratch.hdf5')\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "print('read and compiled model')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "Restore test from cache\n",
      "test length (15945, 224, 224, 3)\n",
      "prediction length  15945\n",
      "test id length  15945\n",
      "iteration:  1\n",
      "Restore test from cache\n",
      "test length (15945, 224, 224, 3)\n",
      "prediction length  31890\n",
      "test id length  31890\n",
      "iteration:  2\n",
      "Restore test from cache\n",
      "test length (15945, 224, 224, 3)\n",
      "prediction length  47835\n",
      "test id length  47835\n",
      "iteration:  3\n",
      "Restore test from cache\n",
      "test length (15945, 224, 224, 3)\n",
      "prediction length  63780\n",
      "test id length  63780\n",
      "iteration:  4\n",
      "Restore test from cache\n",
      "test length (15946, 224, 224, 3)\n",
      "prediction length  79726\n",
      "test id length  79726\n",
      "prediction length  79726\n",
      "Started building csv file\n",
      "successfully created submission\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions=[]\n",
    "test_ids=[]\n",
    "test_splits=5\n",
    "for x in range(test_splits):\n",
    "    print('iteration: ',x)\n",
    "   # cache_path=None\n",
    "    y=x+1\n",
    "    cache_path= os.path.join('cache','test_224_part'+str(y)+'.dat')\n",
    "\n",
    "    if not os.path.isfile(cache_path):\n",
    "        print('building test cache')\n",
    "        test_files,test_id = load_test_parts(x,test_splits)\n",
    "        cache_data((test_files,test_id),cache_path)\n",
    "        print('test cache built')\n",
    "    else:\n",
    "        print('Restore test from cache')\n",
    "        (test_files,test_id)=restore_data(cache_path)\n",
    "    \n",
    "    test_files=np.array(test_files,dtype=np.uint8)    \n",
    "    test_files = test_files.reshape(test_files.shape[0], img_rows, img_cols,img_channel)\n",
    "    test_files = test_files.astype('float32')\n",
    "  \n",
    "    print('test length',test_files.shape)\n",
    "    test_files/=255\n",
    "    \n",
    "    prediction=model.predict(test_files,  batch_size=batch_size)\n",
    "    predictions=append_chunk(predictions,prediction)\n",
    "    test_ids=append_chunk(test_ids,test_id)\n",
    "    del test_files\n",
    "    print('prediction length ',len(predictions))\n",
    "   # np.stack(test_ids,test_id)\n",
    "    print('test id length ',len(test_ids))\n",
    "score=2.022\n",
    "print('prediction length ',len(predictions))\n",
    "create_submission(predictions,test_ids,score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
